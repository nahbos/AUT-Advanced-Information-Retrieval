{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOnZ0SfFtV4mc1fnmsBIjU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nahbos/Advanced-Information-Retrieval/blob/main/Ex01/traditional_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sobhan Moradian Daghigh\n",
        "\n",
        "- 11-22-2022\n",
        "\n",
        "### Ex-01: Traditional methods (WarmUp)"
      ],
      "metadata": {
        "id": "YU-Gx1EmJAA6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "8nmKYHAuI4mA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import re\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "import random\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/nahbos/Advanced-Information-Retrieval/main/Ex01/Data/train_data.csv\n",
        "!wget -nc https://raw.githubusercontent.com/nahbos/Advanced-Information-Retrieval/main/Ex01/Data/valid_data.csv\n",
        "!wget -nc https://raw.githubusercontent.com/nahbos/Advanced-Information-Retrieval/main/Ex01/Data/test_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLtmo5l-I--m",
        "outputId": "097ffd86-060e-4473-c611-a038de21279d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-24 02:43:40--  https://raw.githubusercontent.com/nahbos/Advanced-Information-Retrieval/main/Ex01/Data/train_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5148485 (4.9M) [text/plain]\n",
            "Saving to: ‘train_data.csv’\n",
            "\n",
            "train_data.csv      100%[===================>]   4.91M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-11-24 02:43:42 (49.9 MB/s) - ‘train_data.csv’ saved [5148485/5148485]\n",
            "\n",
            "--2022-11-24 02:43:42--  https://raw.githubusercontent.com/nahbos/Advanced-Information-Retrieval/main/Ex01/Data/valid_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 144317 (141K) [text/plain]\n",
            "Saving to: ‘valid_data.csv’\n",
            "\n",
            "valid_data.csv      100%[===================>] 140.93K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-11-24 02:43:42 (5.05 MB/s) - ‘valid_data.csv’ saved [144317/144317]\n",
            "\n",
            "--2022-11-24 02:43:42--  https://raw.githubusercontent.com/nahbos/Advanced-Information-Retrieval/main/Ex01/Data/test_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131429 (128K) [text/plain]\n",
            "Saving to: ‘test_data.csv’\n",
            "\n",
            "test_data.csv       100%[===================>] 128.35K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-11-24 02:43:43 (4.78 MB/s) - ‘test_data.csv’ saved [131429/131429]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part One. \n",
        "* Data Loading"
      ],
      "metadata": {
        "id": "qWCubj1TKn22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./train_data.csv')\n",
        "val   = pd.read_csv('./valid_data.csv')\n",
        "test  = pd.read_csv('./test_data.csv')"
      ],
      "metadata": {
        "id": "tqkonR1KI-76"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-3CiMaZkI-5J",
        "outputId": "90bf1978-0b72-44d0-e89b-424ffa72821c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0  14    29    30  What are the laws to change your status from a...   \n",
              "1  18    37    38  Why are so many Quora users posting questions ...   \n",
              "2  38    77    78                        How do we prepare for UPSC?   \n",
              "3  58   117   118  I was suddenly logged off Gmail. I can't remem...   \n",
              "4  60   121   122  How do I download content from a kickass torre...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What are the laws to change your status from a...             0  \n",
              "1  Why do people ask Quora questions which can be...             1  \n",
              "2                How do I prepare for civil service?             1  \n",
              "3  I can't remember my Gmail password or my recov...             1  \n",
              "4                   Is Kickass Torrents trustworthy?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d3ebe4f-66e4-4e9d-ad91-2bc11e24d291\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>Why are so many Quora users posting questions ...</td>\n",
              "      <td>Why do people ask Quora questions which can be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>77</td>\n",
              "      <td>78</td>\n",
              "      <td>How do we prepare for UPSC?</td>\n",
              "      <td>How do I prepare for civil service?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>117</td>\n",
              "      <td>118</td>\n",
              "      <td>I was suddenly logged off Gmail. I can't remem...</td>\n",
              "      <td>I can't remember my Gmail password or my recov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>121</td>\n",
              "      <td>122</td>\n",
              "      <td>How do I download content from a kickass torre...</td>\n",
              "      <td>Is Kickass Torrents trustworthy?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d3ebe4f-66e4-4e9d-ad91-2bc11e24d291')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d3ebe4f-66e4-4e9d-ad91-2bc11e24d291 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d3ebe4f-66e4-4e9d-ad91-2bc11e24d291');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww7bis29I-2h",
        "outputId": "d5fcdf4f-06f2-464d-8cf7-7236bc507502"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 37250 entries, 0 to 37249\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            37250 non-null  int64 \n",
            " 1   qid1          37250 non-null  int64 \n",
            " 2   qid2          37250 non-null  int64 \n",
            " 3   question1     37250 non-null  object\n",
            " 4   question2     37250 non-null  object\n",
            " 5   is_duplicate  37250 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En5i5KNJI-zu",
        "outputId": "6a028984-e70f-4b30-f714-eb145b92965b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1010 entries, 0 to 1009\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            1010 non-null   int64 \n",
            " 1   qid1          1010 non-null   int64 \n",
            " 2   qid2          1010 non-null   int64 \n",
            " 3   question1     1010 non-null   object\n",
            " 4   question2     1010 non-null   object\n",
            " 5   is_duplicate  1010 non-null   int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 47.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjNAgw3ZOKUo",
        "outputId": "d18bb4a4-0b0f-4455-f87e-9c397f27a0eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 980 entries, 0 to 979\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            980 non-null    int64 \n",
            " 1   qid1          980 non-null    int64 \n",
            " 2   qid2          980 non-null    int64 \n",
            " 3   question1     980 non-null    object\n",
            " 4   question2     980 non-null    object\n",
            " 5   is_duplicate  980 non-null    int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 46.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jO9P0RZBOKQS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "nvVth-FOiNWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(q):\n",
        "    \n",
        "    q = str(q).lower().strip()\n",
        "    \n",
        "    # Replace certain special characters with their string equivalents\n",
        "    q = q.replace('%', ' percent')\n",
        "    q = q.replace('$', ' dollar ')\n",
        "    q = q.replace('₹', ' rupee ')\n",
        "    q = q.replace('€', ' euro ')\n",
        "    q = q.replace('@', ' at ')\n",
        "    \n",
        "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
        "    q = q.replace('[math]', '')\n",
        "    \n",
        "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
        "    q = q.replace(',000,000,000 ', 'b ')\n",
        "    q = q.replace(',000,000 ', 'm ')\n",
        "    q = q.replace(',000 ', 'k ')\n",
        "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
        "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
        "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
        "    \n",
        "    # Decontracting words\n",
        "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
        "    # https://stackoverflow.com/a/19794953\n",
        "\n",
        "    contractions = { \n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"can't've\": \"can not have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "    }\n",
        "\n",
        "    q_decontracted = []\n",
        "\n",
        "    for word in q.split():\n",
        "        if word in contractions:\n",
        "            word = contractions[word]\n",
        "\n",
        "        q_decontracted.append(word)\n",
        "\n",
        "    q = ' '.join(q_decontracted)\n",
        "    q = q.replace(\"'ve\", \" have\")\n",
        "    q = q.replace(\"n't\", \" not\")\n",
        "    q = q.replace(\"'re\", \" are\")\n",
        "    q = q.replace(\"'ll\", \" will\")\n",
        "    \n",
        "    # Removing HTML tags\n",
        "    q = BeautifulSoup(q)\n",
        "    q = q.get_text()\n",
        "    \n",
        "    # Remove punctuations\n",
        "    pattern = re.compile('\\W')\n",
        "    q = re.sub(pattern, ' ', q).strip()\n",
        "\n",
        "    \n",
        "    return q"
      ],
      "metadata": {
        "id": "4RB0NicKiM0y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['question1'] = train['question1'].apply(preprocess)\n",
        "train['question2'] = train['question2'].apply(preprocess)\n",
        "\n",
        "val['question1'] = val['question1'].apply(preprocess)\n",
        "val['question2'] = val['question2'].apply(preprocess)\n",
        "\n",
        "test['question1'] = test['question1'].apply(preprocess)\n",
        "test['question2'] = test['question2'].apply(preprocess)"
      ],
      "metadata": {
        "id": "z0O0KYAdimCn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dp_frQYWtbxd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ok, Everything looks right ))**"
      ],
      "metadata": {
        "id": "1MqSNvyKOOTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Bua8QINimAL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Two.\n",
        "* Vector Space Retrieval"
      ],
      "metadata": {
        "id": "hv1Bf-OXK1a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = train\n",
        "\n",
        "# Dictionary length\n",
        "#     - with    stop words: 9335\n",
        "#     - without stop words: 9284\n",
        "\n",
        "tokenized_qs = [simple_preprocess(remove_stopwords(q)) for q in dataset.loc[:, 'question2']]\n",
        "dct = Dictionary(tokenized_qs)  # fit dictionary\n",
        "corpus = [dct.doc2bow(tokenized_q) for tokenized_q in tokenized_qs]  # convert corpus to BoW format"
      ],
      "metadata": {
        "id": "Mu_II-1JI-xB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TfidfModel(corpus)        # fit model\n",
        "tfidf_vector = model[corpus]      # apply model to the all corpus document\n",
        "\n",
        "for question in tfidf_vector[:20]:\n",
        "   print([[dct[id], round(freq, 2)] for id, freq in question])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9YDwxPBI-rh",
        "outputId": "c444037c-1f95-4d0c-8a75-82e466a20e0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['card', 0.24], ['change', 0.23], ['compare', 0.16], ['green', 0.24], ['immigration', 0.38], ['japan', 0.28], ['laws', 0.59], ['status', 0.29], ['student', 0.26], ['visa', 0.3]]\n",
            "[['answered', 0.51], ['ask', 0.38], ['easily', 0.42], ['google', 0.4], ['people', 0.28], ['questions', 0.33], ['quora', 0.26]]\n",
            "[['civil', 0.63], ['prepare', 0.5], ['service', 0.59]]\n",
            "[['email', 0.34], ['gmail', 0.33], ['mail', 0.43], ['password', 0.32], ['recover', 0.38], ['recovery', 0.4], ['remember', 0.42]]\n",
            "[['kickass', 0.55], ['torrents', 0.5], ['trustworthy', 0.67]]\n",
            "[['bad', 0.43], ['book', 0.36], ['new', 0.26], ['rowling', 0.79]]\n",
            "[['english', 0.37], ['fluently', 0.63], ['learn', 0.43], ['speak', 0.54]]\n",
            "[['actually', 0.55], ['life', 0.69], ['purpose', 0.47]]\n",
            "[['compare', 0.2], ['cambodia', 0.29], ['earthquake', 0.58], ['effects', 0.53], ['major', 0.26], ['valparaiso', 0.44]]\n",
            "[['india', 0.3], ['nuclear', 0.71], ['pakistan', 0.49], ['war', 0.41]]\n",
            "[['ask', 0.36], ['getting', 0.51], ['improve', 0.3], ['marked', 0.44], ['need', 0.45], ['question', 0.35]]\n",
            "[['questions', 0.44], ['quora', 0.35], ['answering', 0.83]]\n",
            "[['compare', 0.18], ['battle', 0.78], ['contrast', 0.26], ['riyadh', 0.4], ['significance', 0.26], ['somme', 0.26]]\n",
            "[['estate', 0.33], ['impact', 0.32], ['market', 0.34], ['notes', 0.18], ['real', 0.28], ['rupee', 0.66], ['scrapping', 0.36]]\n",
            "[['quora', 0.48], ['earn', 0.72], ['money', 0.5]]\n",
            "[['cancel', 0.37], ['got', 0.31], ['list', 0.27], ['railway', 0.43], ['refund', 0.36], ['reservation', 0.37], ['tatkal', 0.34], ['waiting', 0.36]]\n",
            "[['conserved', 0.31], ['created', 0.24], ['energy', 0.65], ['expanding', 0.29], ['infinite', 0.47], ['potential', 0.27], ['universe', 0.24]]\n",
            "[['book', 0.38], ['good', 0.31], ['publish', 0.69], ['ways', 0.31], ['write', 0.43]]\n",
            "[['gmail', 0.35], ['password', 0.34], ['recover', 0.4], ['remember', 0.45], ['account', 0.63]]\n",
            "[['cancel', 0.49], ['list', 0.36], ['tatkal', 0.45], ['waiting', 0.48], ['ticket', 0.44]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O8WSWAHn9lr6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since the Gensim dosent support for max_features, so for rest of the implementation, Im gonna use sklearn instead.**\n"
      ],
      "metadata": {
        "id": "LVnHASMu9hra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
        "tfidf_matrix_train = tr_vectorizer.fit_transform(train.loc[:, 'question2'])\n",
        "print(tfidf_matrix_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjqRUi8B8-hy",
        "outputId": "82a593d1-bee8-4743-df68-736e3c8d154a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37250, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_vectorizer = TfidfVectorizer(vocabulary=tr_vectorizer.vocabulary_, stop_words='english')\n",
        "tfidf_matrix_test = ts_vectorizer.fit_transform(test.loc[:, 'question1'])\n",
        "print(tfidf_matrix_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B24OQ1A_Tr7",
        "outputId": "983b8ed7-3e11-4768-f928-191fbe4e0e06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(980, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity(tfidf_matrix_test, tfidf_matrix_train)\n",
        "similarity.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okKWNcNSgY6A",
        "outputId": "6b3a634d-1352-455c-a8fb-2d21de8aff2a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(980, 37250)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_questions(test_data, train_data, similarity_matrix, n_sim=10, samples=None):\n",
        "  for i, test_q in enumerate(similarity_matrix):\n",
        "    if samples is None or i in samples:\n",
        "      check_duplicated_qs = []\n",
        "      bests = np.argsort(test_q.tolist())[::-1]\n",
        "      print('\\n-', test_data.loc[i, 'question1'])\n",
        "      for best in bests:\n",
        "        q = train_data.loc[best, 'question2']\n",
        "        if q not in check_duplicated_qs:\n",
        "          print('  > ', q)\n",
        "          check_duplicated_qs.append(q)\n",
        "          if len(check_duplicated_qs) == n_sim:\n",
        "            break"
      ],
      "metadata": {
        "id": "bdnT1Bm4idlW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(2)\n",
        "random_tests = random.sample(range(0, len(test)), 5)\n",
        "get_similar_questions(test, train, similarity, samples=random_tests)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N7AqLEjVUOB",
        "outputId": "db8f978d-4d06-47b9-fa01-a39e72ab5625"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- who will win the election in united states\n",
            "  >  who will win the 2016 united states presidential election  trump or clinton\n",
            "  >  who is the coolest first lady of the united states\n",
            "  >  who will win the us election\n",
            "  >  who will win uttar pradesh election\n",
            "  >  who should be the next president of the united states\n",
            "  >  who do you think will win the u s  election in november\n",
            "  >  who will win the us election in 2016\n",
            "  >  does the president of the united states have a food taster\n",
            "  >  who will win 2017 uttar pradesh election and why\n",
            "  >  who will win up 2017 election\n",
            "\n",
            "- how do i recover my gmail account when it does not open after password reset\n",
            "  >  how can i recover my gmail account s password\n",
            "  >  how do you recover your gmail account password\n",
            "  >  how do i reset my gmail account password\n",
            "  >  how can i reset the password for my gmail account\n",
            "  >  how do i recover my gmail password\n",
            "  >  how can you recover your gmail password\n",
            "  >  how do i reset my gmail password\n",
            "  >  how do i reset a gmail password\n",
            "  >  how to reset password for gmail via sms\n",
            "  >  i do not remember my password to my gmail account  how can i recover my account\n",
            "\n",
            "- is it possible to stop masturbating\n",
            "  >  how can i stop masturbating\n",
            "  >  how should i stop masturbating\n",
            "  >  how can one stop masturbating for good\n",
            "  >  how should a guy stop masturbating\n",
            "  >  how can i stop masturbations\n",
            "  >  how can i stop being lazy\n",
            "  >  how can i stop being lazy and useless\n",
            "  >  how can one stop being a procrastinator\n",
            "  >  how can i stop myself from leaning forward on a squat\n",
            "  >  is timetravel possible\n",
            "\n",
            "- what does it take to be a top writer on quora\n",
            "  >  how does someone become a top writer in quora  criteria\n",
            "  >  how can i become a top writer on quora\n",
            "  >  what should i do to become a top writer on quora\n",
            "  >  how do you become the top writer on quora\n",
            "  >  how does a quora writer qualify as a top writer  and get those gifts\n",
            "  >  how does one withdraw from quora\n",
            "  >  why does quora not have emoji s\n",
            "  >  how can i become a top question writer on quora\n",
            "  >  what should i do to become a top writer on quora in 2017\n",
            "  >  what should a writer do for inspiration when they are experiencing writer s block\n",
            "\n",
            "- how can i trace phone calls from a cell phone\n",
            "  >  how do i trace a phone call\n",
            "  >  how can i locate my cell phone with the phone number\n",
            "  >  how can i find out who tapped into my phone\n",
            "  >  how can i activate a verizon phone with a call\n",
            "  >  how do you activate a verizon phone over the phone\n",
            "  >  is it possible to trace a scammers  phone call\n",
            "  >  how can you hack a cell phone\n",
            "  >  is there a phone number i can call to see if my phone tapped\n",
            "  >  how can we trace a phone call s origin or cellphone location\n",
            "  >  what are the best pics clicked on a phone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CS4Z3DZQUYIP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Three.\n",
        "* Language Model Retrieval"
      ],
      "metadata": {
        "id": "f3qd7s2cLGRq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01TvDsKbyKym"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(N / (N + mu)) * (TFw,D / |D|) \n",
        "\n",
        "\\+ (mu / (N + mu)) * (CFw / |c|)\n"
      ],
      "metadata": {
        "id": "1O17rGzNHcJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_word_given_doc(word, doc, collection, collection_length, collection_freq, _lambda=10):\n",
        "    doc_tf = doc.count(word)\n",
        "    document_length = max(len(doc.split()), 1)\n",
        "    collection_tf = collection_freq.get(word)\n",
        "\n",
        "    return np.add(np.multiply(np.divide(document_length, np.add(document_length, _lambda)), \n",
        "                              np.divide(doc_tf, document_length)), \n",
        "                  np.multiply(np.divide(_lambda, np.add(document_length, _lambda)), \n",
        "                              np.divide(collection_tf, collection_length)))"
      ],
      "metadata": {
        "id": "UYYd34JeyAoE"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_qs_train = [simple_preprocess(remove_stopwords(q)) for q in train.loc[:, 'question2']]\n",
        "tokenized_qs_val   = [simple_preprocess(remove_stopwords(q)) for q in   val.loc[:, 'question1']]\n",
        "\n",
        "collection = ' '.join(' '.join(ele) for ele in tokenized_qs_train)  # Stop words removed\n",
        "collection_freq = dict(Counter(collection.split()))\n",
        "collection_length = len(collection_freq)\n",
        "\n",
        "for i, val_q in enumerate(tokenized_qs_val[:3]):\n",
        "    scores = []\n",
        "    for train_q in tqdm(tokenized_qs_train):\n",
        "        prob = 1\n",
        "        for token in val_q:\n",
        "            prob = np.multiply(prob, probability_word_given_doc(word=token, doc=' '.join(train_q), collection=collection, collection_length=collection_length, collection_freq=collection_freq))\n",
        "        scores.append(prob)\n",
        "\n",
        "    print('\\nValidation: ', val.loc[i, 'question1'])\n",
        "    print('Train:      ', train.loc[:, 'question2'][np.argsort(scores)[::-1][0]])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQxYk7xrSg3W",
        "outputId": "f4a260de-0f21-4db7-f448-3f6aef56e079"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37250/37250 [00:09<00:00, 3986.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation:  realistically speaking  what would happen to the usa if donald trump wins presidency in the 2016 elections\n",
            "Train:       what will happen to the superpower status of the usa  if donald trump wins the 2016 presidential elections\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37250/37250 [00:02<00:00, 14413.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation:  does global warming exist\n",
            "Train:       was global warming replaced by climate change because they found there was no global warming\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37250/37250 [00:02<00:00, 14129.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation:  how do i make india as corruption free\n",
            "Train:       what i can do for corruption free india\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90On7alxYLQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d36k8cXUYLOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0PwkicOYLLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Four.\n",
        "* Evaluation Metrics"
      ],
      "metadata": {
        "id": "NCUft9j5LSYS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xe4r0vuhI-UD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfSRwwyVI-Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pm0tLP6tI-PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finito"
      ],
      "metadata": {
        "id": "yhZLAhGvLdRJ"
      }
    }
  ]
}